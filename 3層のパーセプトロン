import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report
import matplotlib.pyplot as plt

# --- データ生成 ---
# 2クラス分類のデータセットを作成
X, y = make_classification(n_samples=1000, n_features=2, n_classes=2, random_state=42, n_informative=2, n_redundant=0)

# データをトレーニングセットとテストセットに分割
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# データを正規化
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# --- モデル定義 ---
# 入力層、隠れ層（ReLU活性化）、出力層（シグモイド活性化）
model = Sequential([
    Dense(10, input_dim=2, activation='relu', name="Hidden_Layer"),  # 隠れ層
    Dense(1, activation='sigmoid', name="Output_Layer")             # 出力層
])

# モデルのコンパイル
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# --- モデル学習 ---
history = model.fit(X_train, y_train, epochs=50, batch_size=10, verbose=0, validation_split=0.2)

# --- 評価 ---
# テストセットでの評価
loss, accuracy = model.evaluate(X_test, y_test, verbose=0)
print(f"Test Accuracy: {accuracy:.2f}")

# --- 分類レポート ---
# 予測と評価
y_pred = (model.predict(X_test) > 0.5).astype(int).ravel()
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# --- 可視化 ---
# 損失のプロット
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title("Loss over Epochs")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()
plt.grid()

# 精度のプロット
plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title("Accuracy over Epochs")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.grid()

plt.tight_layout()
plt.show()

# --- 決定境界の可視化 ---
def plot_decision_boundary(X, y, model):
    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),
                         np.arange(y_min, y_max, 0.01))
    grid = np.c_[xx.ravel(), yy.ravel()]
    preds = model.predict(grid).reshape(xx.shape)
    plt.contourf(xx, yy, preds, alpha=0.7, cmap="viridis")
    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolor='k', cmap="viridis")
    plt.title("Decision Boundary")
    plt.xlabel("Feature 1")
    plt.ylabel("Feature 2")
    plt.grid()
    plt.show()

plot_decision_boundary(X_test, y_test, model)
